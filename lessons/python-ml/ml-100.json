{
  "id": "ml-100",
  "title": "Transfer Learning",
  "category": "Deep Learning",
  "number": 100,
  "duration": "15 min read",
  "content": "## Transfer Learning\n\nTransfer Learning involves taking a pre-trained model (a model trained on a large dataset like ImageNet) and repurposing it for a specific task.\n\n### Why use it?\n\n1.  **Less Data**: Works well even with small datasets.\n2.  **Faster Training**: The model has already learned feature extraction (edges, shapes).\n3.  **Better Performance**: Often achieves higher accuracy.\n\n### How to use it\n\n1.  **Load Pre-trained Model**: Load a model like VGG16, ResNet50, or MobileNet without the top (classification) layers.\n2.  **Freeze Layers**: Prevent the weights of the base model from being updated during initial training.\n3.  **Add Custom Head**: Add your own dense layers for your specific classes.\n4.  **Fine-tuning**: Optionally unfreeze some top layers of the base model and train with a very low learning rate.\n\n```python\nfrom tensorflow.keras.applications import MobileNetV2\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False # Freeze\n\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(1, activation='sigmoid')\n])\n```\n",
  "code": "import tensorflow as tf\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n\n# TODO: Load MobileNetV2 with imagenet weights, exclude top, input_shape=(160, 160, 3)\nbase_model = MobileNetV2(input_shape=(160, 160, 3),\n                         include_top=False,\n                         weights='imagenet')\n\n# TODO: Freeze the base_model\nbase_model.trainable = False\n\n# TODO: Create the new model\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.summary()"
}