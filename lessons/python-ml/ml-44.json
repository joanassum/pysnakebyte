{
  "id": "ml-44",
  "title": "The ML Workflow",
  "category": "ML Fundamentals",
  "number": 44,
  "duration": "10 min read",
  "content": "## The Complete Machine Learning Workflow\n\nBuilding ML models follows a systematic process from problem definition to deployment.\n\n## Step 1: Define the Problem\n\n```python\n# Before writing any code, answer these questions:\n\nml_problem_checklist = {\n    'Business Question': 'What problem are we trying to solve?',\n    'Success Metric': 'How will we measure success?',\n    'ML Framing': 'Is this classification, regression, or clustering?',\n    'Data Availability': 'What data do we have access to?',\n    'Baseline': 'What is the current solution or benchmark?'\n}\n\nprint(\"=== Problem Definition Checklist ===\")\nfor item, question in ml_problem_checklist.items():\n    print(f\"\\n{item}:\")\n    print(f\"  {question}\")\n\n# Example Problem:\nexample_problem = {\n    'Business Question': 'Predict customer churn to enable proactive retention',\n    'Success Metric': 'Reduce churn rate by 20%, achieve 80%+ recall',\n    'ML Framing': 'Binary classification (churn / no churn)',\n    'Data Availability': 'Customer transactions, demographics, support tickets',\n    'Baseline': 'Current rule-based system catches 40% of churners'\n}\n\nprint(\"\\n=== Example: Customer Churn ===\")\nfor item, answer in example_problem.items():\n    print(f\"{item}: {answer}\")\n```\n\n## Step 2: Collect and Explore Data\n\n```python\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Generate sample customer data\nnp.random.seed(42)\nn = 1000\n\ndf = pd.DataFrame({\n    'customer_id': range(n),\n    'tenure_months': np.random.exponential(24, n),\n    'monthly_charges': np.random.normal(65, 20, n).clip(20, 120),\n    'total_charges': lambda x: x['tenure_months'] * x['monthly_charges'],\n    'support_tickets': np.random.poisson(2, n),\n    'contract_type': np.random.choice(['month-to-month', 'one_year', 'two_year'], n, \n                                       p=[0.5, 0.3, 0.2])\n})\ndf['total_charges'] = df['tenure_months'] * df['monthly_charges']\n```",
  "code": "import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\n\n# Complete ML Workflow Example\nnp.random.seed(42)\n\n# Step 1: Define Problem\nprint(\"STEP 1: Define Problem\")\nprint(\"Goal: Predict loan default risk\")\n\n# Step 2: Generate/Load Data\nprint(\"\\nSTEP 2: Load Data\")\nn = 500\ndf = pd.DataFrame({\n    'income': np.random.normal(60000, 20000, n).clip(20000),\n    'debt_ratio': np.random.uniform(0.1, 0.6, n),\n    'credit_score': np.random.normal(680, 50, n).clip(500, 800),\n    'loan_amount': np.random.uniform(5000, 50000, n)\n})\ndefault_prob = 0.1 + 0.3*(df['debt_ratio'] > 0.4) + 0.2*(df['credit_score'] < 650)\ndf['default'] = (np.random.random(n) < default_prob).astype(int)\n\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Default rate: {df['default'].mean():.2%}\")\n\n# Step 3: Prepare Data\nprint(\"\\nSTEP 3: Prepare Data\")\nX = df.drop('default', axis=1)\ny = df['default']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Step 4: Train Model\nprint(\"\\nSTEP 4: Train Model\")\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_scaled, y_train)\n\n# Step 5: Evaluate\nprint(\"\\nSTEP 5: Evaluate Model\")\nprint(f\"Accuracy: {model.score(X_test_scaled, y_test):.4f}\")\nprint(classification_report(y_test, model.predict(X_test_scaled)))\n\n# Try: Add feature importance analysis"
}
