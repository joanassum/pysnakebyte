{
  "id": "ml-79",
  "title": "Multi-class Classification",
  "category": "Classification Algorithms",
  "number": 79,
  "duration": "12 min read",
  "content": "## Multi-class Classification\n\nSome algorithms (like Random Forest, Naive Bayes) can handle multiple classes naturally. Others (like SVM, Logistic Regression) are binary by nature. To use binary classifiers for multi-class problems, we use strategies like OvR or OvO.\n\n### Strategies\n\n1.  **One-vs-Rest (OvR) / One-vs-All**: Train $N$ binary classifiers, one for each class vs the rest. The class with the highest confidence score wins. Most common strategy.\n2.  **One-vs-One (OvO)**: Train $N(N-1)/2$ binary classifiers for every pair of classes. The class that wins the most duels is chosen. Good for algorithms that scale poorly with dataset size (like SVM).\n\n### Scikit-Learn Handling\n\nScikit-Learn usually handles this automatically. For example, `LogisticRegression` uses OvR by default for multi-class targets.\n\n```python\n# Explicitly specifying OvR\nmodel = LogisticRegression(multi_class='ovr')\n\n# Using the OneVsRestClassifier wrapper\nfrom sklearn.multiclass import OneVsRestClassifier\novr = OneVsRestClassifier(SVC())\novr.fit(X_train, y_train)\n```\n",
  "code": "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndata = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 1. One-vs-Rest Strategy with SVM\nprint(\"Training OvR SVM...\")\novr_clf = OneVsRestClassifier(SVC())\novr_clf.fit(X_train, y_train)\nprint(f\"OvR Accuracy: {ovr_clf.score(X_test, y_test):.4f}\")\n\n# 2. One-vs-One Strategy with SVM\nprint(\"Training OvO SVM...\")\novo_clf = OneVsOneClassifier(SVC())\novo_clf.fit(X_train, y_train)\nprint(f\"OvO Accuracy: {ovo_clf.score(X_test, y_test):.4f}\")"
}