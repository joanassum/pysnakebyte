{
  "id": "ml-72",
  "title": "K-Nearest Neighbors",
  "category": "Classification Algorithms",
  "number": 72,
  "duration": "10 min read",
  "content": "## K-Nearest Neighbors (KNN)\n\nK-Nearest Neighbors is a simple, non-parametric, and lazy learning algorithm. It classifies a new data point based on the majority class of its 'K' nearest neighbors in the feature space.\n\n### How it Works\n\n1.  **Choose K**: Select the number of neighbors (K).\n2.  **Calculate Distance**: Compute the distance (Euclidean, Manhattan, etc.) between the new point and all training points.\n3.  **Find Neighbors**: Identify the K points with the smallest distances.\n4.  **Vote**: Classify the new point based on the majority vote of the neighbors.\n\n### Choosing K\n\n*   **Small K**: Sensitive to noise, can lead to overfitting.\n*   **Large K**: Smoother decision boundary, can lead to underfitting.\n*   **Odd K**: Usually preferred to avoid ties in binary classification.\n\n### Pros and Cons\n\n*   **Pros**: Simple to understand, no training phase (lazy learning).\n*   **Cons**: Computationally expensive at prediction time, sensitive to scale of data (requires scaling).\n\n### Implementation\n\n```python\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\n\n# KNN is sensitive to scale, so we use a pipeline with scaler\nknn_pipeline = make_pipeline(\n    StandardScaler(),\n    KNeighborsClassifier(n_neighbors=5)\n)\n\nknn_pipeline.fit(X_train, y_train)\n```\n",
  "code": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndata = load_iris()\nX, y = data.data, data.target\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 1. Initialize StandardScaler to scale the data\nscaler = StandardScaler()\n\n# 2. Fit and transform training data, transform test data\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# 3. Initialize KNN with n_neighbors=3\nknn = KNeighborsClassifier(n_neighbors=3)\n\n# 4. Train and predict\nknn.fit(X_train_scaled, y_train)\ny_pred = knn.predict(X_test_scaled)\n\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
}